# Configuração para execução local (sem Docker)
# Copie este arquivo para .env.local e ajuste conforme necessário

# Ambiente
NODE_ENV=development

# Portas dos serviços
API_GATEWAY_PORT=3000
ORCHESTRATOR_PORT=3001
AGENT1_PORT=3002
AGENT2_PORT=3003

# JWT
JWT_SECRET=sua-chave-secreta-jwt-muito-segura-aqui-local-dev

# OpenAI (opcional - deixe vazio se não tiver)
OPENAI_API_KEY=

# URLs dos serviços (localhost)
ORCHESTRATOR_URL=http://localhost:3001
AGENT1_URL=http://localhost:3002
AGENT2_URL=http://localhost:3003
API_GATEWAY_URL=http://localhost:3000

# Ollama (para Agent 1 - se usando localmente)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama2

# Configurações de logging
LOG_LEVEL=info
LOG_FORMAT=combined

# Timeouts (em milissegundos)
REQUEST_TIMEOUT=30000
AGENT_TIMEOUT=10000

# Configurações de saúde
HEALTH_CHECK_INTERVAL=30000

# Configurações de segurança
RATE_LIMIT_WINDOW=900000
RATE_LIMIT_MAX=100

# Configurações de desenvolvimento
CORS_ORIGIN=http://localhost:3000
CORS_CREDENTIALS=true

# Configurações específicas para execução local
LOCAL_EXECUTION=true
DEBUG_MODE=true
VERBOSE_LOGGING=true
